{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, plot_confusion_matrix, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import datasets\n",
    "from stellargraph.mapper import (\n",
    "    CorruptedGenerator,\n",
    "    FullBatchNodeGenerator,\n",
    "    GraphSAGENodeGenerator,\n",
    "    HinSAGENodeGenerator,\n",
    "    Node2VecNodeGenerator,\n",
    "    ClusterNodeGenerator,\n",
    ")\n",
    "from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE, Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model, optimizers, losses, metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, BorderlineSMOTE, KMeansSMOTE, SMOTENC, SVMSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import multiprocessing\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded. Loading it from file system\n",
      "LOADING DATA: 1.01 s\n",
      "PREPROCESSING: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "v_data, e_data, v_sets, e_sets, core_targets, ext_targets, core_testing = utils.load_for_jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account :\n",
      "-1.0    126863\n",
      " 0.0     13769\n",
      " 1.0      1244\n",
      "Name: testingFlag, dtype: int64\n",
      "Address :\n",
      "-1.0    28432\n",
      " 0.0     1568\n",
      "Name: testingFlag, dtype: int64\n",
      "Customer :\n",
      "-1.0    42127\n",
      " 0.0    13650\n",
      " 1.0      449\n",
      "Name: testingFlag, dtype: int64\n",
      "Derived Entity :\n",
      "-1.0    27286\n",
      " 0.0     3925\n",
      " 1.0       63\n",
      "Name: testingFlag, dtype: int64\n",
      "External Entity :\n",
      "-1.0    55207\n",
      " 0.0     4757\n",
      " 1.0       36\n",
      "Name: testingFlag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sort based on testingFlag\n",
    "for i in v_sets:\n",
    "    v_sets[i] = v_sets[i].sort_values('testingFlag')\n",
    "    print(i,\":\")\n",
    "    print(v_sets[i].testingFlag.value_counts())\n",
    "    v_sets[i] = v_sets[i].drop('testingFlag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ExtendedCaseID:\n",
    "\n",
    "for i in v_sets:\n",
    "    v_sets[i] = v_sets[i].drop('ExtendedCaseGraphID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 15\n",
    "num_samples = [8, 4]\n",
    "dropout = 0.5\n",
    "hinsage_layer_sizes = [32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = sg.StellarDiGraph(v_sets, e_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = HinSAGENodeGenerator(\n",
    "    G, \n",
    "    batch_size, \n",
    "    num_samples,\n",
    "    head_node_type=\"Account\"\n",
    ")\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=hinsage_layer_sizes,\n",
    "    activations=['relu', 'softmax'],\n",
    "    generator=generator, \n",
    "    bias=True,\n",
    "    normalize=\"l2\",\n",
    "    dropout=dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_graph_infomax(base_model, generator, epochs):\n",
    "    t0 = time.time()\n",
    "    corrupted_generator = CorruptedGenerator(generator)\n",
    "    gen = corrupted_generator.flow(G.nodes(node_type=\"Account\"))\n",
    "    infomax = DeepGraphInfomax(base_model, corrupted_generator)\n",
    "\n",
    "    x_in, x_out = infomax.in_out_tensors()\n",
    "\n",
    "    # Train DGI\n",
    "    model = Model(inputs=x_in, outputs=x_out)\n",
    "    model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer=Adam(lr=1e-3))\n",
    "    es = EarlyStopping(monitor=\"loss\", min_delta=0, patience=15)\n",
    "    history = model.fit(gen, epochs=epochs, verbose=1, callbacks=[es])\n",
    "    sg.utils.plot_history(history)\n",
    "\n",
    "    x_emb_in, x_emb_out = base_model.in_out_tensors()\n",
    "    if generator.num_batch_dims() == 2:\n",
    "        x_emb_out = tf.squeeze(x_emb_out, axis=0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f'Time required: {t1-t0:.2f} s ({(t1-t0)/60:.1f} min)')\n",
    "    \n",
    "    return x_emb_in, x_emb_out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "355/355 [==============================] - 213s 599ms/step - loss: 0.5992\n",
      "Epoch 2/15\n",
      "355/355 [==============================] - 203s 572ms/step - loss: 0.5527\n",
      "Epoch 3/15\n",
      "355/355 [==============================] - 204s 575ms/step - loss: 0.5242\n",
      "Epoch 4/15\n",
      "138/355 [==========>...................] - ETA: 2:04 - loss: 0.5087"
     ]
    }
   ],
   "source": [
    "# Run Deep Graph Infomax\n",
    "\n",
    "x_emb_in, x_emb_out, model = run_deep_graph_infomax(hinsage, generator, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT\n",
    "\n",
    "train_cv_set = v_sets['Account'][126863:126863+13769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Model(inputs=x_emb_in, outputs=x_emb_out)\n",
    "train_cv_embs = emb_model.predict(\n",
    "    generator.flow(train_cv_set.index.values)\n",
    ")\n",
    "train_cv_embs_2d = pd.DataFrame(\n",
    "    TSNE(n_components=2).fit_transform(train_cv_embs), \n",
    "    index=train_cv_set.index.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloring based on ExtendedCaseGraphID\n",
    "\n",
    "# these are the training+cv indexes\n",
    "node_ids = train_cv_set.index.values.tolist()\n",
    "\n",
    "# these are the training+cv Extended case ID\n",
    "ext_targets_2 = v_sample.loc[[int(node_id) for node_id in node_ids]].ExtendedCaseGraphID \n",
    "\n",
    "label_map = {l: i*10 for i, l in enumerate(np.unique(ext_targets_2), start=10) if pd.notna(l)}\n",
    "node_colours = [label_map[target] if pd.notna(target) else 0 for target in ext_targets_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.scatter(\n",
    "    train_cv_embs_2d[0],\n",
    "    train_cv_embs_2d[1],\n",
    "    c=node_colours,\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax.set(aspect=\"equal\")\n",
    "plt.title(\"TSNE visualization of HinSAGE embeddings with Deep Graph Infomax - coloring on ExtendedCaseGraphID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node degree based coloring\n",
    "\n",
    "# these are the training+cv source degrees\n",
    "ext_targets_3 = v_sample.loc[[int(node_id) for node_id in node_ids]].source_degree\n",
    "\n",
    "label_map = {l: i*100 for i, l in enumerate(np.unique(ext_targets_3), start=10) if pd.notna(l)}\n",
    "node_colours = [label_map[target] if pd.notna(target) else 0 for target in ext_targets_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.scatter(\n",
    "    train_cv_embs_2d[0],\n",
    "    train_cv_embs_2d[1],\n",
    "    c=node_colours,\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax.set(aspect=\"equal\")\n",
    "plt.title(\"TSNE visualization of HinSAGE embeddings with Deep Graph Infomax - coloring based on node source degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account core case ID based coloring\n",
    "\n",
    "# these are the training+cv core case IDs\n",
    "ext_targets_5 = v_sample.loc[[int(node_id) for node_id in node_ids]]['CoreCaseGraphID']\n",
    "\n",
    "label_map = {l: i*100 for i, l in enumerate(np.unique(ext_targets_5), start=10) if pd.notna(l)}\n",
    "node_colours = [label_map[target] if pd.notna(target) else 0 for target in ext_targets_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.scatter(\n",
    "    train_cv_embs_2d[0],\n",
    "    train_cv_embs_2d[1],\n",
    "    c=node_colours,\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax.set(aspect=\"equal\")\n",
    "plt.title(\"TSNE visualization of HinSAGE embeddings with Deep Graph Infomax - coloring based on CoreCaseGraphID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very rudimentary and shitty splitting:\n",
    "\n",
    "n_embs = train_cv_embs.shape[0]\n",
    "\n",
    "train_set = train_cv_embs[:10000]\n",
    "train_labels = ext_targets_2.values[:10000]\n",
    "\n",
    "cv_set = train_cv_embs[-3769:]\n",
    "cv_labels = ext_targets_2.values[-3769:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CLASSIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.ones(10000)\n",
    "sample_weights[0] = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY GRADIENT BOOSTING CLASSIFIER\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(\n",
    "    X=train_set,\n",
    "    y=train_labels,\n",
    "    sample_weight=sample_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pred = classifier.predict(cv_set)\n",
    "f1_avg = f1_score(cv_labels, cv_pred, average='micro')\n",
    "acc = (cv_pred == cv_labels).mean()\n",
    "\n",
    "print(f\"f1: {f1_avg:.3f} - acc: {acc:.3f}\")\n",
    "\n",
    "confusion_matrix = pd.crosstab(\n",
    "    cv_labels,\n",
    "    cv_pred,\n",
    "    rownames=['True'],\n",
    "    colnames=['Predicted'],\n",
    "    margins=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(6, 10)})\n",
    "plt.spy(confusion_matrix, precision = 0.1, markersize = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
